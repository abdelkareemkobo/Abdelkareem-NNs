[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "About",
    "section": "",
    "text": "I am an experiential learner who dreams, designs and builds exceptional, high-quality digital products and services. I also train machines to teach themselves."
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Abdelkareem NNs",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\n\n\ncnn\n\n\ndeep_learning\n\n\ncomputer_vision\n\n\npytorch\n\n\n\n\n\n\n\n\n\n\n\nOct 8, 2022\n\n\n9 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/buildcnn/index.html",
    "href": "posts/buildcnn/index.html",
    "title": "Building an CNN with Pytorch",
    "section": "",
    "text": "Data Augmentation\nIn simple words, it is a measure to increase the number of training examples by slightly modifying the existing examples. For example, you could duplicate the instances currently available and add some noise to those duplicates to make sure they are not exactly the same. In computer vision problems, this means incrementing the number of images in the training dataset by altering the existing images, which can be done by slightly altering the current images to create duplicated versions that are slightly different These minor adjustments to the images can be in the form of slight rotations, changes in the position of the object in the frame, horizontal or vertical flips, different color schemes, and distortions, among others. This technique works considering that CNNs will consider each of these images a different image.\n\nimport numpy as np\nimport torch\nfrom torch import nn, optim\nimport torch.nn.functional as F\nfrom torchvision import datasets\nimport torchvision.transforms as transforms\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom sklearn.metrics import accuracy_score\nimport matplotlib.pyplot as plt\n\n\ntransform = {\n    \"train\": transforms.Compose([\n        transforms.RandomHorizontalFlip(0.5), \n        transforms.RandomGrayscale(0.1),\n        transforms.ToTensor(),\n        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]),\n    \"test\": transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])}\n\n\nConvert the pixels into tensor datatype and normalizing the data\n\nbatch_size = 100\n\ntrain_data = datasets.CIFAR10('data3', train=True, download=True, transform=transform[\"train\"])\ntest_data = datasets.CIFAR10('data3', train=False, download=True, transform=transform[\"test\"])\n\nbatch_size = 100 downloading the data set from datasets module train_data = datasets.CIFAR10(‘data’, train=True, download=True, transform=transform) test_data = datasets.CIFAR10(‘data’, train=False, download=True, transform=transform)\ndev_size = 0.2 Using a validation size of 20%, define the training and validation sampler that will be used to divide the dataset into those two sets. idx = list(range(len(train_data))) np.random.shuffle(idx) split_size = int(np.floor(dev_size * len(train_data))) train_idx, dev_idx = idx[split_size:], idx[:split_size]\n\ntrain_sampler = SubsetRandomSampler(train_idx)\ndev_sampler = SubsetRandomSampler(dev_idx)\nThe SubsetRandomSampler() function from pytorch is used to divide the original training set into training and validations by randomly sampling indexes.\n\n\ndev_size = 0.2\nidx = list(range(len(train_data)))\nnp.random.shuffle(idx)\nsplit_size = int(np.floor(dev_size * len(train_data)))\ntrain_idx, dev_idx = idx[split_size:], idx[:split_size]\n\ntrain_sampler = SubsetRandomSampler(train_idx)\ndev_sampler = SubsetRandomSampler(dev_idx)\n\n\nThe DataLoader() functions are the ones in charge of loading the images by batches.The resulting variables(train_loader,dev_loader,and test_loader) of this function will contain the values for the features and the target separately.\n\n\ntrain_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=train_sampler)\ndev_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=dev_sampler)\ntest_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size)\n\n\n\nDefine the architecture of your network. Use the following information to do so:\n• Conv1: A convolutional layer that takes as input the colored image and passes it through 10 filters of size 3. Both the padding and the stride should be set to 1.\n• Conv2: A convolutional layer that passes the input data through 20 filters of size 3. Both the padding and the stride should be set to 1.\n• Conv3: A convolutional layer that passes the input data through 40 filters of size three. Both the padding and the stride should be set to 1.\n• Use the ReLU activation function after each convolutional layer.\n• A pooling layer after each convolutional layer, with a filter size and stride of 2.\n• A dropout term set to 20% after flattening the image.\n• Linear1: A fully-connected layer that receives as input the flattened matrix from the previous layer and generates an output of 100 units. Use the ReLU activation function for this layer. A dropout term here is set to 20%.\n• Linear2: A fully-connected layer that generates 10 outputs, one for each class label. Use the log_softmax activation function for the output layer.\n\nclass CNN(nn.Module):\n    def __init__(self):\n        super(CNN, self).__init__()\n        self.conv1 = nn.Conv2d(3, 10, 3, 1, 1)\n        self.norm1 = nn.BatchNorm2d(10)\n        self.conv2 = nn.Conv2d(10, 20, 3, 1, 1)\n        self.norm2 = nn.BatchNorm2d(20)\n        self.conv3 = nn.Conv2d(20, 40, 3, 1, 1)\n        self.norm3 = nn.BatchNorm2d(40)\n        self.pool = nn.MaxPool2d(2, 2)\n        \n        self.linear1 = nn.Linear(40 * 4 * 4, 100)\n        self.norm4 = nn.BatchNorm1d(100)\n        self.linear2 = nn.Linear(100, 10)\n        self.dropout = nn.Dropout(0.2)\n\n    def forward(self, x):\n        x = self.pool(self.norm1(F.relu(self.conv1(x))))\n        x = self.pool(self.norm2(F.relu(self.conv2(x))))\n        x = self.pool(self.norm3(F.relu(self.conv3(x))))\n\n        x = x.view(-1, 40 * 4 * 4)\n        x = self.dropout(x)\n        x = self.norm4(F.relu(self.linear1(x)))\n        x = self.dropout(x)\n        x = F.log_softmax(self.linear2(x), dim=1)\n        \n        return x\n\n\nmodel = CNN()\nloss_function = nn.NLLLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\nepochs = 100\n\n\nTrain your network and be sure to save the values for the loss and accuracy of both the training and validation sets.\n\n\ntrain_losses, dev_losses, train_acc, dev_acc= [], [], [], []\nx_axis = []\n\nfor e in range(1, epochs+1):\n    losses = 0\n    acc = 0\n    iterations = 0\n    \n    model.train()\n    for data, target in train_loader:\n        iterations += 1\n\n        pred = model(data)\n        loss = loss_function(pred, target)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        losses += loss.item()\n        p = torch.exp(pred)\n        top_p, top_class = p.topk(1, dim=1)\n        acc += accuracy_score(target, top_class)\n        \n    dev_losss = 0\n    dev_accs = 0\n    iter_2 = 0\n        \n    if e%5 == 0 or e == 1:\n        x_axis.append(e)\n        \n        with torch.no_grad():\n            model.eval()\n            \n            for data_dev, target_dev in dev_loader:\n                iter_2 += 1\n                \n                dev_pred = model(data_dev)\n                dev_loss = loss_function(dev_pred, target_dev)\n                dev_losss += dev_loss.item()\n\n                dev_p = torch.exp(dev_pred)\n                top_p, dev_top_class = dev_p.topk(1, dim=1)\n                dev_accs += accuracy_score(target_dev, dev_top_class)\n        \n        train_losses.append(losses/iterations)\n        dev_losses.append(dev_losss/iter_2)\n        train_acc.append(acc/iterations)\n        dev_acc.append(dev_accs/iter_2)\n        \n        print(\"Epoch: {}/{}.. \".format(e, epochs),\n              \"Training Loss: {:.3f}.. \".format(losses/iterations),\n              \"Validation Loss: {:.3f}.. \".format(dev_losss/iter_2),\n              \"Training Accuracy: {:.3f}.. \".format(acc/iterations),\n              \"Validation Accuracy: {:.3f}\".format(dev_accs/iter_2))\n\n\nPlot the loss and accuracy of both sets\n\n\nplt.plot(x_axis,train_losses, label='Training loss')\nplt.plot(x_axis, dev_losses, label='Validation loss')\nplt.legend(frameon=False)\nplt.show()\n\n\nplt.plot(x_axis, train_acc, label=\"Training accuracy\")\nplt.plot(x_axis, dev_acc, label=\"Validation accuracy\")\nplt.legend(frameon=False)\nplt.show()\n\n\nmodel.eval()\niter_3 = 0\nacc_test = 0\nfor data_test, target_test in test_loader:\n    iter_3 += 1\n    test_pred = model(data_test)\n    test_pred = torch.exp(test_pred)\n    top_p, top_class_test = test_pred.topk(1, dim=1)\n    acc_test += accuracy_score(target_test, top_class_test)\nprint(acc_test/iter_3)"
  }
]