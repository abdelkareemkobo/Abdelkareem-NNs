[
  {
    "objectID": "posts/buildcnn/index.html#checky-your-dependices",
    "href": "posts/buildcnn/index.html#checky-your-dependices",
    "title": "Post With Code",
    "section": "\nchecky your dependices\n",
    "text": "checky your dependices\n\n\n\nimport numpy as np\nimport torch\nfrom torch import nn, optim\nimport torch.nn.functional as F\nfrom torchvision import datasets\nimport torchvision.transforms as transforms\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom sklearn.metrics import accuracy_score\nimport matplotlib.pyplot as plt\n\n\n/home/kemo/anaconda3/envs/python10/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n\n\n\n\ntransform = {\n    \"train\": transforms.Compose([\n        transforms.RandomHorizontalFlip(0.5), \n        transforms.RandomGrayscale(0.1),\n        transforms.ToTensor(),\n        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]),\n    \"test\": transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])}\n\n\n\n\nbatch_size = 100\n\ntrain_data = datasets.CIFAR10('data3', train=True, download=True, transform=transform[\"train\"])\ntest_data = datasets.CIFAR10('data3', train=False, download=True, transform=transform[\"test\"])\n\n\nDownloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data3/cifar-10-python.tar.gz\n\n\n\n\n\nKeyboardInterrupt: \n\n\n\n\ndev_size = 0.2\nidx = list(range(len(train_data)))\nnp.random.shuffle(idx)\nsplit_size = int(np.floor(dev_size * len(train_data)))\ntrain_idx, dev_idx = idx[split_size:], idx[:split_size]\n\ntrain_sampler = SubsetRandomSampler(train_idx)\ndev_sampler = SubsetRandomSampler(dev_idx)\n\n\n\n\ntrain_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=train_sampler)\ndev_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=dev_sampler)\ntest_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size)\n\n\n\n\nclass CNN(nn.Module):\n    def __init__(self):\n        super(CNN, self).__init__()\n        self.conv1 = nn.Conv2d(3, 10, 3, 1, 1)\n        self.norm1 = nn.BatchNorm2d(10)\n        self.conv2 = nn.Conv2d(10, 20, 3, 1, 1)\n        self.norm2 = nn.BatchNorm2d(20)\n        self.conv3 = nn.Conv2d(20, 40, 3, 1, 1)\n        self.norm3 = nn.BatchNorm2d(40)\n        self.pool = nn.MaxPool2d(2, 2)\n        \n        self.linear1 = nn.Linear(40 * 4 * 4, 100)\n        self.norm4 = nn.BatchNorm1d(100)\n        self.linear2 = nn.Linear(100, 10)\n        self.dropout = nn.Dropout(0.2)\n\n    def forward(self, x):\n        x = self.pool(self.norm1(F.relu(self.conv1(x))))\n        x = self.pool(self.norm2(F.relu(self.conv2(x))))\n        x = self.pool(self.norm3(F.relu(self.conv3(x))))\n\n        x = x.view(-1, 40 * 4 * 4)\n        x = self.dropout(x)\n        x = self.norm4(F.relu(self.linear1(x)))\n        x = self.dropout(x)\n        x = F.log_softmax(self.linear2(x), dim=1)\n        \n        return x\n\n\n\n\nmodel = CNN()\nloss_function = nn.NLLLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\nepochs = 100\n\n\n\n\ntrain_losses, dev_losses, train_acc, dev_acc= [], [], [], []\nx_axis = []\n\nfor e in range(1, epochs+1):\n    losses = 0\n    acc = 0\n    iterations = 0\n    \n    model.train()\n    for data, target in train_loader:\n        iterations += 1\n\n        pred = model(data)\n        loss = loss_function(pred, target)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        losses += loss.item()\n        p = torch.exp(pred)\n        top_p, top_class = p.topk(1, dim=1)\n        acc += accuracy_score(target, top_class)\n        \n    dev_losss = 0\n    dev_accs = 0\n    iter_2 = 0\n        \n    if e%5 == 0 or e == 1:\n        x_axis.append(e)\n        \n        with torch.no_grad():\n            model.eval()\n            \n            for data_dev, target_dev in dev_loader:\n                iter_2 += 1\n                \n                dev_pred = model(data_dev)\n                dev_loss = loss_function(dev_pred, target_dev)\n                dev_losss += dev_loss.item()\n\n                dev_p = torch.exp(dev_pred)\n                top_p, dev_top_class = dev_p.topk(1, dim=1)\n                dev_accs += accuracy_score(target_dev, dev_top_class)\n        \n        train_losses.append(losses/iterations)\n        dev_losses.append(dev_losss/iter_2)\n        train_acc.append(acc/iterations)\n        dev_acc.append(dev_accs/iter_2)\n        \n        print(\"Epoch: {}/{}.. \".format(e, epochs),\n              \"Training Loss: {:.3f}.. \".format(losses/iterations),\n              \"Validation Loss: {:.3f}.. \".format(dev_losss/iter_2),\n              \"Training Accuracy: {:.3f}.. \".format(acc/iterations),\n              \"Validation Accuracy: {:.3f}\".format(dev_accs/iter_2))\n\n\nEpoch: 1/100..  Training Loss: 1.452..  Validation Loss: 1.147..  Training Accuracy: 0.483..  Validation Accuracy: 0.587\nEpoch: 5/100..  Training Loss: 0.903..  Validation Loss: 0.832..  Training Accuracy: 0.682..  Validation Accuracy: 0.712\nEpoch: 10/100..  Training Loss: 0.779..  Validation Loss: 0.760..  Training Accuracy: 0.726..  Validation Accuracy: 0.734\nEpoch: 15/100..  Training Loss: 0.720..  Validation Loss: 0.713..  Training Accuracy: 0.748..  Validation Accuracy: 0.752\nEpoch: 20/100..  Training Loss: 0.674..  Validation Loss: 0.701..  Training Accuracy: 0.764..  Validation Accuracy: 0.753\nEpoch: 25/100..  Training Loss: 0.654..  Validation Loss: 0.688..  Training Accuracy: 0.772..  Validation Accuracy: 0.762\nEpoch: 30/100..  Training Loss: 0.627..  Validation Loss: 0.667..  Training Accuracy: 0.780..  Validation Accuracy: 0.772\nEpoch: 35/100..  Training Loss: 0.605..  Validation Loss: 0.669..  Training Accuracy: 0.786..  Validation Accuracy: 0.769\nEpoch: 40/100..  Training Loss: 0.595..  Validation Loss: 0.689..  Training Accuracy: 0.790..  Validation Accuracy: 0.764\nEpoch: 45/100..  Training Loss: 0.576..  Validation Loss: 0.660..  Training Accuracy: 0.795..  Validation Accuracy: 0.775\nEpoch: 50/100..  Training Loss: 0.570..  Validation Loss: 0.673..  Training Accuracy: 0.799..  Validation Accuracy: 0.768\nEpoch: 55/100..  Training Loss: 0.564..  Validation Loss: 0.661..  Training Accuracy: 0.801..  Validation Accuracy: 0.776\nEpoch: 60/100..  Training Loss: 0.554..  Validation Loss: 0.663..  Training Accuracy: 0.803..  Validation Accuracy: 0.775\nEpoch: 65/100..  Training Loss: 0.540..  Validation Loss: 0.647..  Training Accuracy: 0.807..  Validation Accuracy: 0.778\nEpoch: 70/100..  Training Loss: 0.542..  Validation Loss: 0.673..  Training Accuracy: 0.807..  Validation Accuracy: 0.772\nEpoch: 75/100..  Training Loss: 0.540..  Validation Loss: 0.654..  Training Accuracy: 0.809..  Validation Accuracy: 0.781\nEpoch: 80/100..  Training Loss: 0.533..  Validation Loss: 0.653..  Training Accuracy: 0.812..  Validation Accuracy: 0.780\nEpoch: 85/100..  Training Loss: 0.523..  Validation Loss: 0.653..  Training Accuracy: 0.814..  Validation Accuracy: 0.780\nEpoch: 90/100..  Training Loss: 0.523..  Validation Loss: 0.652..  Training Accuracy: 0.815..  Validation Accuracy: 0.780\nEpoch: 95/100..  Training Loss: 0.522..  Validation Loss: 0.646..  Training Accuracy: 0.813..  Validation Accuracy: 0.781\nEpoch: 100/100..  Training Loss: 0.507..  Validation Loss: 0.644..  Training Accuracy: 0.821..  Validation Accuracy: 0.782\n\n\n\n\nplt.plot(x_axis,train_losses, label='Training loss')\nplt.plot(x_axis, dev_losses, label='Validation loss')\nplt.legend(frameon=False)\nplt.show()\n\n\n\n\n\n\n\n\n\nplt.plot(x_axis, train_acc, label=\"Training accuracy\")\nplt.plot(x_axis, dev_acc, label=\"Validation accuracy\")\nplt.legend(frameon=False)\nplt.show()\n\n\n\n\n\n\n\n\n\nmodel.eval()\niter_3 = 0\nacc_test = 0\nfor data_test, target_test in test_loader:\n    iter_3 += 1\n    test_pred = model(data_test)\n    test_pred = torch.exp(test_pred)\n    top_p, top_class_test = test_pred.topk(1, dim=1)\n    acc_test += accuracy_score(target_test, top_class_test)\nprint(acc_test/iter_3)\n\n\n0.7865000000000001"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Abdelkareem NNs",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nOct 8, 2022\n\n\n17 min\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nOct 8, 2022\n\n\n3 min\n\n\n\n\n\n\nNo matching items"
  }
]